{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "b052177e",
      "metadata": {},
      "source": [
        "## Importing All The Necessary Stuff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "995c239a",
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "34d08244",
      "metadata": {},
      "source": [
        "## Loading The Data to prepare a Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "8a0bf074",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the data from CSV file\n",
        "# df = pd.read_csv(r\"D:\\Stuff\\CyberSec\\archive\\03-02-2018.csv\")\n",
        "df = pd.read_csv(r\"..\\Datasets\\IDS2018\\02-14-2018.csv\")\n",
        "\n",
        "# Remove any rows with missing values\n",
        "# df = df.dropna()\n",
        "\n",
        "# Drop columns where all values are 0\n",
        "# df = df.loc[:, (df != 0).any(axis=0)]\n",
        "\n",
        "columns = list(df.columns)\n",
        "\n",
        "# to select first n rows only\n",
        "# df = df.iloc[:500000,:]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fde9390b",
      "metadata": {},
      "source": [
        "### Display the Imported Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "14db7062",
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Dst Port</th>\n",
              "      <th>Protocol</th>\n",
              "      <th>Timestamp</th>\n",
              "      <th>Flow Duration</th>\n",
              "      <th>Tot Fwd Pkts</th>\n",
              "      <th>Tot Bwd Pkts</th>\n",
              "      <th>TotLen Fwd Pkts</th>\n",
              "      <th>TotLen Bwd Pkts</th>\n",
              "      <th>Fwd Pkt Len Max</th>\n",
              "      <th>Fwd Pkt Len Min</th>\n",
              "      <th>...</th>\n",
              "      <th>Fwd Seg Size Min</th>\n",
              "      <th>Active Mean</th>\n",
              "      <th>Active Std</th>\n",
              "      <th>Active Max</th>\n",
              "      <th>Active Min</th>\n",
              "      <th>Idle Mean</th>\n",
              "      <th>Idle Std</th>\n",
              "      <th>Idle Max</th>\n",
              "      <th>Idle Min</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14/02/2018 08:31:01</td>\n",
              "      <td>112641719</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56320859.5</td>\n",
              "      <td>139.300036</td>\n",
              "      <td>56320958</td>\n",
              "      <td>56320761</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14/02/2018 08:33:50</td>\n",
              "      <td>112641466</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56320733.0</td>\n",
              "      <td>114.551299</td>\n",
              "      <td>56320814</td>\n",
              "      <td>56320652</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>14/02/2018 08:36:39</td>\n",
              "      <td>112638623</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>56319311.5</td>\n",
              "      <td>301.934596</td>\n",
              "      <td>56319525</td>\n",
              "      <td>56319098</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>14/02/2018 08:40:13</td>\n",
              "      <td>6453966</td>\n",
              "      <td>15</td>\n",
              "      <td>10</td>\n",
              "      <td>1239</td>\n",
              "      <td>2273</td>\n",
              "      <td>744</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22</td>\n",
              "      <td>6</td>\n",
              "      <td>14/02/2018 08:40:23</td>\n",
              "      <td>8804066</td>\n",
              "      <td>14</td>\n",
              "      <td>11</td>\n",
              "      <td>1143</td>\n",
              "      <td>2209</td>\n",
              "      <td>744</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>32</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Benign</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows Ã— 80 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   Dst Port  Protocol            Timestamp  Flow Duration  Tot Fwd Pkts  \\\n",
              "0         0         0  14/02/2018 08:31:01      112641719             3   \n",
              "1         0         0  14/02/2018 08:33:50      112641466             3   \n",
              "2         0         0  14/02/2018 08:36:39      112638623             3   \n",
              "3        22         6  14/02/2018 08:40:13        6453966            15   \n",
              "4        22         6  14/02/2018 08:40:23        8804066            14   \n",
              "\n",
              "   Tot Bwd Pkts  TotLen Fwd Pkts  TotLen Bwd Pkts  Fwd Pkt Len Max  \\\n",
              "0             0                0                0                0   \n",
              "1             0                0                0                0   \n",
              "2             0                0                0                0   \n",
              "3            10             1239             2273              744   \n",
              "4            11             1143             2209              744   \n",
              "\n",
              "   Fwd Pkt Len Min  ...  Fwd Seg Size Min  Active Mean  Active Std  \\\n",
              "0                0  ...                 0          0.0         0.0   \n",
              "1                0  ...                 0          0.0         0.0   \n",
              "2                0  ...                 0          0.0         0.0   \n",
              "3                0  ...                32          0.0         0.0   \n",
              "4                0  ...                32          0.0         0.0   \n",
              "\n",
              "   Active Max  Active Min   Idle Mean    Idle Std  Idle Max  Idle Min   Label  \n",
              "0           0           0  56320859.5  139.300036  56320958  56320761  Benign  \n",
              "1           0           0  56320733.0  114.551299  56320814  56320652  Benign  \n",
              "2           0           0  56319311.5  301.934596  56319525  56319098  Benign  \n",
              "3           0           0         0.0    0.000000         0         0  Benign  \n",
              "4           0           0         0.0    0.000000         0         0  Benign  \n",
              "\n",
              "[5 rows x 80 columns]"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# display the dataframe\n",
        "df.head()\n",
        "# df"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7dc6be8d",
      "metadata": {},
      "source": [
        "### Printing all the Features available in our Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "82200578",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Feature 1:\t\"Dst Port\"\n",
            "Feature 2:\t\"Protocol\"\n",
            "Feature 3:\t\"Timestamp\"\n",
            "Feature 4:\t\"Flow Duration\"\n",
            "Feature 5:\t\"Tot Fwd Pkts\"\n",
            "Feature 6:\t\"Tot Bwd Pkts\"\n",
            "Feature 7:\t\"TotLen Fwd Pkts\"\n",
            "Feature 8:\t\"TotLen Bwd Pkts\"\n",
            "Feature 9:\t\"Fwd Pkt Len Max\"\n",
            "Feature 10:\t\"Fwd Pkt Len Min\"\n",
            "Feature 11:\t\"Fwd Pkt Len Mean\"\n",
            "Feature 12:\t\"Fwd Pkt Len Std\"\n",
            "Feature 13:\t\"Bwd Pkt Len Max\"\n",
            "Feature 14:\t\"Bwd Pkt Len Min\"\n",
            "Feature 15:\t\"Bwd Pkt Len Mean\"\n",
            "Feature 16:\t\"Bwd Pkt Len Std\"\n",
            "Feature 17:\t\"Flow Byts/s\"\n",
            "Feature 18:\t\"Flow Pkts/s\"\n",
            "Feature 19:\t\"Flow IAT Mean\"\n",
            "Feature 20:\t\"Flow IAT Std\"\n",
            "Feature 21:\t\"Flow IAT Max\"\n",
            "Feature 22:\t\"Flow IAT Min\"\n",
            "Feature 23:\t\"Fwd IAT Tot\"\n",
            "Feature 24:\t\"Fwd IAT Mean\"\n",
            "Feature 25:\t\"Fwd IAT Std\"\n",
            "Feature 26:\t\"Fwd IAT Max\"\n",
            "Feature 27:\t\"Fwd IAT Min\"\n",
            "Feature 28:\t\"Bwd IAT Tot\"\n",
            "Feature 29:\t\"Bwd IAT Mean\"\n",
            "Feature 30:\t\"Bwd IAT Std\"\n",
            "Feature 31:\t\"Bwd IAT Max\"\n",
            "Feature 32:\t\"Bwd IAT Min\"\n",
            "Feature 33:\t\"Fwd PSH Flags\"\n",
            "Feature 34:\t\"Bwd PSH Flags\"\n",
            "Feature 35:\t\"Fwd URG Flags\"\n",
            "Feature 36:\t\"Bwd URG Flags\"\n",
            "Feature 37:\t\"Fwd Header Len\"\n",
            "Feature 38:\t\"Bwd Header Len\"\n",
            "Feature 39:\t\"Fwd Pkts/s\"\n",
            "Feature 40:\t\"Bwd Pkts/s\"\n",
            "Feature 41:\t\"Pkt Len Min\"\n",
            "Feature 42:\t\"Pkt Len Max\"\n",
            "Feature 43:\t\"Pkt Len Mean\"\n",
            "Feature 44:\t\"Pkt Len Std\"\n",
            "Feature 45:\t\"Pkt Len Var\"\n",
            "Feature 46:\t\"FIN Flag Cnt\"\n",
            "Feature 47:\t\"SYN Flag Cnt\"\n",
            "Feature 48:\t\"RST Flag Cnt\"\n",
            "Feature 49:\t\"PSH Flag Cnt\"\n",
            "Feature 50:\t\"ACK Flag Cnt\"\n",
            "Feature 51:\t\"URG Flag Cnt\"\n",
            "Feature 52:\t\"CWE Flag Count\"\n",
            "Feature 53:\t\"ECE Flag Cnt\"\n",
            "Feature 54:\t\"Down/Up Ratio\"\n",
            "Feature 55:\t\"Pkt Size Avg\"\n",
            "Feature 56:\t\"Fwd Seg Size Avg\"\n",
            "Feature 57:\t\"Bwd Seg Size Avg\"\n",
            "Feature 58:\t\"Fwd Byts/b Avg\"\n",
            "Feature 59:\t\"Fwd Pkts/b Avg\"\n",
            "Feature 60:\t\"Fwd Blk Rate Avg\"\n",
            "Feature 61:\t\"Bwd Byts/b Avg\"\n",
            "Feature 62:\t\"Bwd Pkts/b Avg\"\n",
            "Feature 63:\t\"Bwd Blk Rate Avg\"\n",
            "Feature 64:\t\"Subflow Fwd Pkts\"\n",
            "Feature 65:\t\"Subflow Fwd Byts\"\n",
            "Feature 66:\t\"Subflow Bwd Pkts\"\n",
            "Feature 67:\t\"Subflow Bwd Byts\"\n",
            "Feature 68:\t\"Init Fwd Win Byts\"\n",
            "Feature 69:\t\"Init Bwd Win Byts\"\n",
            "Feature 70:\t\"Fwd Act Data Pkts\"\n",
            "Feature 71:\t\"Fwd Seg Size Min\"\n",
            "Feature 72:\t\"Active Mean\"\n",
            "Feature 73:\t\"Active Std\"\n",
            "Feature 74:\t\"Active Max\"\n",
            "Feature 75:\t\"Active Min\"\n",
            "Feature 76:\t\"Idle Mean\"\n",
            "Feature 77:\t\"Idle Std\"\n",
            "Feature 78:\t\"Idle Max\"\n",
            "Feature 79:\t\"Idle Min\"\n",
            "Feature 80:\t\"Label\"\n"
          ]
        }
      ],
      "source": [
        "# Print column names with their respective column numbers\n",
        "for i, col_name in enumerate(df.columns):\n",
        "    print(f\"Feature {i+1}:\\t\\\"{col_name}\\\"\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "93897eee",
      "metadata": {},
      "source": [
        "## Decision Tree"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "9ed8fa60",
      "metadata": {
        "scrolled": false
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the following features combined ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow IAT Mean', 'Bwd IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd Pkts/s', 'FIN Flag Cnt', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Pkts/b Avg', 'Subflow Bwd Pkts'] is: 0.9999666213670935\n"
          ]
        }
      ],
      "source": [
        "# specify column indexes to select\n",
        "selected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\n",
        "\n",
        "selected_cols_idx = [x - 1 for x in selected_cols_idx]\n",
        "\n",
        "# select columns by index using iloc\n",
        "X = df.iloc[:, selected_cols_idx].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the decision tree classifier\n",
        "clf = DecisionTreeClassifier()\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier\n",
        "accuracy = clf.score(X_test, y_test)\n",
        "\n",
        "# Get the names of the selected columns\n",
        "selected_cols = list(df.columns[selected_cols_idx])\n",
        "\n",
        "print(\"Accuracy for the following features combined\", selected_cols, \"is:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "47bd292e",
      "metadata": {},
      "source": [
        "## KNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "2a6e7063",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the following features combined ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow IAT Mean', 'Bwd IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd Pkts/s', 'FIN Flag Cnt', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Pkts/b Avg', 'Subflow Bwd Pkts'] is: 0.9997091290561\n"
          ]
        }
      ],
      "source": [
        "# specify column indexes to select\n",
        "selected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\n",
        "selected_cols_idx = [x - 1 for x in selected_cols_idx]\n",
        "\n",
        "# select columns by index using iloc\n",
        "X = df.iloc[:, selected_cols_idx].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the KNN classifier\n",
        "knn = KNeighborsClassifier()\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "\n",
        "# Get the names of the selected columns\n",
        "selected_cols = list(df.columns[selected_cols_idx])\n",
        "\n",
        "print(\"Accuracy for the following features combined\", selected_cols, \"is:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "d4ed65de",
      "metadata": {},
      "source": [
        "## Weighted KNN \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "08879e73",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the following features combined ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow IAT Mean', 'Bwd IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd Pkts/s', 'FIN Flag Cnt', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Pkts/b Avg', 'Subflow Bwd Pkts'] is: 0.9998235700832082\n"
          ]
        }
      ],
      "source": [
        "# specify column indexes to select\n",
        "selected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\n",
        "selected_cols_idx = [x - 1 for x in selected_cols_idx]\n",
        "\n",
        "# select columns by index using iloc\n",
        "X = df.iloc[:, selected_cols_idx].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the weighted KNN classifier\n",
        "knn = KNeighborsClassifier(weights='distance')\n",
        "knn.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier\n",
        "accuracy = knn.score(X_test, y_test)\n",
        "\n",
        "# Get the names of the selected columns\n",
        "selected_cols = list(df.columns[selected_cols_idx])\n",
        "\n",
        "print(\"Accuracy for the following features combined\", selected_cols, \"is:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "fb01ed0f",
      "metadata": {},
      "source": [
        "## Random Forest"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "dea65b94",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the following features combined ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow IAT Mean', 'Bwd IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd Pkts/s', 'FIN Flag Cnt', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Pkts/b Avg', 'Subflow Bwd Pkts'] is: 0.999971389743223\n"
          ]
        }
      ],
      "source": [
        "# specify column indexes to select\n",
        "selected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\n",
        "selected_cols_idx = [x - 1 for x in selected_cols_idx]\n",
        "\n",
        "# select columns by index using iloc\n",
        "X = df.iloc[:, selected_cols_idx].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Random Forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier\n",
        "accuracy = rf.score(X_test, y_test)\n",
        "\n",
        "# Get the names of the selected columns\n",
        "selected_cols = list(df.columns[selected_cols_idx])\n",
        "\n",
        "print(\"Accuracy for the following features combined\", selected_cols, \"is:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "16aa7d06",
      "metadata": {},
      "source": [
        "## Gaussian Naive Bayes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "acec5d7c",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the following features combined ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow IAT Mean', 'Bwd IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd Pkts/s', 'FIN Flag Cnt', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Pkts/b Avg', 'Subflow Bwd Pkts'] is: 0.4937796533390554\n"
          ]
        }
      ],
      "source": [
        "# Specify column indexes to select\n",
        "selected_cols_idx = [1,2,4,5,6,11,15,19,29,33,34,35,40,46,48,58,59,62,66]\n",
        "selected_cols_idx = [x - 1 for x in selected_cols_idx]\n",
        "\n",
        "# Select columns by index using iloc\n",
        "X = df.iloc[:, selected_cols_idx].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the Gaussian Naive Bayes classifier\n",
        "gnb = GaussianNB()\n",
        "gnb.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier\n",
        "accuracy = gnb.score(X_test, y_test)\n",
        "\n",
        "# Get the names of the selected columns\n",
        "selected_cols = list(df.columns[selected_cols_idx])\n",
        "\n",
        "print(\"Accuracy for the following features combined\", selected_cols, \"is:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "c00fe888",
      "metadata": {},
      "source": [
        "## MLP \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "41eabb10",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the following features combined ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow IAT Mean', 'Bwd IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd Pkts/s', 'FIN Flag Cnt', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Pkts/b Avg', 'Subflow Bwd Pkts'] is: 0.76881958848914\n"
          ]
        }
      ],
      "source": [
        "# specify column indexes to select\n",
        "selected_cols_idx = [1, 2, 4, 5, 6, 11, 15, 19, 29, 33, 34, 35, 40, 46, 48, 58, 59, 62, 66]\n",
        "selected_cols_idx = [x - 1 for x in selected_cols_idx]\n",
        "\n",
        "# select columns by index using iloc\n",
        "X = df.iloc[:, selected_cols_idx].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# instantiate the MLP classifier\n",
        "mlp = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=300, alpha=0.0001,\n",
        "                    solver='adam', random_state=42, tol=0.0001)\n",
        "\n",
        "# train the MLP classifier\n",
        "mlp.fit(X_train, y_train)\n",
        "\n",
        "# test the MLP classifier\n",
        "accuracy = mlp.score(X_test, y_test)\n",
        "\n",
        "# get the names of the selected columns\n",
        "selected_cols = list(df.columns[selected_cols_idx])\n",
        "\n",
        "print(\"Accuracy for the following features combined\", selected_cols, \"is:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "28fe006e",
      "metadata": {},
      "source": [
        "## QDA "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "cc2e57fc",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Accuracy for the following features combined ['Dst Port', 'Protocol', 'Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Mean', 'Bwd Pkt Len Mean', 'Flow IAT Mean', 'Bwd IAT Mean', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd Pkts/s', 'FIN Flag Cnt', 'RST Flag Cnt', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Bwd Pkts/b Avg', 'Subflow Bwd Pkts'] is: 0.7561166344801278\n"
          ]
        }
      ],
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "\n",
        "# specify column indexes to select\n",
        "selected_cols_idx = [1, 2, 4, 5, 6, 11, 15, 19, 29, 33, 34, 35, 40, 46, 48, 58, 59, 62, 66]\n",
        "selected_cols_idx = [x - 1 for x in selected_cols_idx]\n",
        "\n",
        "# select columns by index using iloc\n",
        "X = df.iloc[:, selected_cols_idx].values\n",
        "y = df.iloc[:, -1].values\n",
        "\n",
        "# split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# scale the data\n",
        "scaler = StandardScaler()\n",
        "X_train = scaler.fit_transform(X_train)\n",
        "X_test = scaler.transform(X_test)\n",
        "\n",
        "# instantiate the QDA classifier\n",
        "qda = QuadraticDiscriminantAnalysis(reg_param=0.1)\n",
        "\n",
        "# train the QDA classifier\n",
        "qda.fit(X_train, y_train)\n",
        "\n",
        "# test the QDA classifier\n",
        "accuracy = qda.score(X_test, y_test)\n",
        "\n",
        "# get the names of the selected columns\n",
        "selected_cols = list(df.columns[selected_cols_idx])\n",
        "\n",
        "print(\"Accuracy for the following features combined\", selected_cols, \"is:\", accuracy)\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "id": "1b1ca059",
      "metadata": {},
      "source": [
        "## GAN MODEL\n",
        "(HAVE TO IMPORT DATASET OF KAGGLE MICROSOFT MALWARE CLASSIFICATION CHALLENGE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "250ad9db",
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Dense, Input, Reshape, Flatten, Dropout, LeakyReLU\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Load data\n",
        "data = pd.read_csv('malware_data.csv')\n",
        "\n",
        "# Remove missing values\n",
        "data = data.dropna()\n",
        "\n",
        "# Convert categorical columns to numeric\n",
        "for col in data.select_dtypes('object').columns:\n",
        "    data[col] = pd.Categorical(data[col]).codes\n",
        "\n",
        "# Split data into X and y\n",
        "X = data.drop('HasDetections', axis=1).values.astype(np.float32)\n",
        "y = data['HasDetections'].values.astype(np.float32)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the generator network\n",
        "def make_generator():\n",
        "    model = Sequential([\n",
        "        Dense(256, input_shape=(100,), activation='relu'),\n",
        "        Dense(512, activation='relu'),\n",
        "        Dense(X.shape[1], activation='tanh')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Define the discriminator network\n",
        "def make_discriminator():\n",
        "    model = Sequential([\n",
        "        Dense(512, input_shape=(X.shape[1],), activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(256, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "    return model\n",
        "\n",
        "# Compile the discriminator\n",
        "discriminator = make_discriminator()\n",
        "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Define the GAN\n",
        "generator = make_generator()\n",
        "discriminator.trainable = False\n",
        "gan_input = Input(shape=(100,))\n",
        "fake_data = generator(gan_input)\n",
        "gan_output = discriminator(fake_data)\n",
        "gan = Model(gan_input, gan_output)\n",
        "gan.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\n",
        "# Train the GAN\n",
        "epochs = 10000\n",
        "batch_size = 32\n",
        "for epoch in range(epochs):\n",
        "    # Generate noise\n",
        "    noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
        "    \n",
        "    # Generate fake data\n",
        "    fake_data = generator.predict(noise)\n",
        "    \n",
        "    # Combine real and fake data\n",
        "    X_combined = np.concatenate([X_train, fake_data])\n",
        "    y_combined = np.concatenate([y_train, np.zeros(batch_size)])\n",
        "    \n",
        "    # Train discriminator\n",
        "    discriminator_loss = discriminator.train_on_batch(X_combined, y_combined)\n",
        "    \n",
        "    # Generate new noise\n",
        "    noise = np.random.normal(0, 1, size=[batch_size, 100])\n",
        "    \n",
        "    # Set labels to 'real' (i.e. 1)\n",
        "    y_mislabeled = np.ones(batch_size)\n",
        "    \n",
        "    # Train generator\n",
        "    generator_loss = gan.train_on_batch(noise, y_mislabeled)\n",
        "    \n",
        "    # Print loss every 100 epochs\n",
        "    if epoch % 100 == 0:\n",
        "        print(f\"Epoch: {epoch}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")\n",
        "    \n",
        "# Generate fake data and test the classifier\n",
        "noise = np.random.normal(0, 1, size=[X_test.shape[0], 100])\n",
        "fake_data = generator.predict(noise)\n",
        "accuracy = discriminator.evaluate(X_test,\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
