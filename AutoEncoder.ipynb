{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "080e3430",
   "metadata": {},
   "source": [
    "# Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2ea1a8f",
   "metadata": {},
   "source": [
    "## Importing the necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0e52bdf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0f6531e",
   "metadata": {},
   "source": [
    "## Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c399b898",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('processed_final.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b751614b",
   "metadata": {},
   "source": [
    "## Splitting data into training and validation sets and Normalizing input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aadea19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_data = data.sample(frac=0.8, random_state=42)\n",
    "val_data = data.drop(train_data.index)\n",
    "\n",
    "# Normalize input data\n",
    "scaler = StandardScaler()\n",
    "train_X = scaler.fit_transform(train_data.drop('Label', axis=1))\n",
    "val_X = scaler.transform(val_data.drop('Label', axis=1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da656d63",
   "metadata": {},
   "source": [
    "## Defining Autoencoder Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "460b2829",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = train_X.shape[1]\n",
    "encoding_dim = 32\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder_layer = Dense(encoding_dim, activation='relu')(input_layer)\n",
    "decoder_layer = Dense(input_dim, activation='sigmoid')(encoder_layer)\n",
    "\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa5cb246",
   "metadata": {},
   "source": [
    "## Compiling model with adam optimizer and mae loss "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15b0580e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "autoencoder.compile(optimizer='adam', loss='mae')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9540484e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1633/1633 [==============================] - 8s 4ms/step - loss: 0.3229 - val_loss: 0.2969\n",
      "Epoch 2/10\n",
      "1633/1633 [==============================] - 6s 4ms/step - loss: 0.2956 - val_loss: 0.2946\n",
      "Epoch 3/10\n",
      "1633/1633 [==============================] - 5s 3ms/step - loss: 0.2941 - val_loss: 0.2939\n",
      "Epoch 4/10\n",
      "1633/1633 [==============================] - 6s 4ms/step - loss: 0.2937 - val_loss: 0.2936\n",
      "Epoch 5/10\n",
      "1633/1633 [==============================] - 6s 4ms/step - loss: 0.2934 - val_loss: 0.2934\n",
      "Epoch 6/10\n",
      "1633/1633 [==============================] - 7s 4ms/step - loss: 0.2932 - val_loss: 0.2932\n",
      "Epoch 7/10\n",
      "1633/1633 [==============================] - 7s 4ms/step - loss: 0.2931 - val_loss: 0.2931\n",
      "Epoch 8/10\n",
      "1633/1633 [==============================] - 6s 4ms/step - loss: 0.2920 - val_loss: 0.2919\n",
      "Epoch 9/10\n",
      "1633/1633 [==============================] - 7s 4ms/step - loss: 0.2918 - val_loss: 0.2918\n",
      "Epoch 10/10\n",
      "1633/1633 [==============================] - 6s 4ms/step - loss: 0.2917 - val_loss: 0.2918\n"
     ]
    }
   ],
   "source": [
    "epochs = 10\n",
    "batch_size = 512\n",
    "\n",
    "history = autoencoder.fit(train_X, train_X,\n",
    "                          epochs=epochs,\n",
    "                          batch_size=batch_size,\n",
    "                          shuffle=True,\n",
    "                          validation_data=(val_X, val_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f66f0260",
   "metadata": {},
   "source": [
    "## Evaluating the performance of the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "02bb05a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6530/6530 [==============================] - 13s 2ms/step - loss: 0.2918\n",
      "Validation loss:  0.29175302386283875\n"
     ]
    }
   ],
   "source": [
    "val_loss = autoencoder.evaluate(val_X, val_X)\n",
    "print(\"Validation loss: \", val_loss)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c8232fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6530/6530 [==============================] - 11s 2ms/step\n",
      "Mean reconstruction error:  0.2917527237017866\n"
     ]
    }
   ],
   "source": [
    "val_preds = autoencoder.predict(val_X)\n",
    "val_mae = np.mean(np.abs(val_preds - val_X), axis=1)\n",
    "mean_recon_error = np.mean(val_mae)\n",
    "print(\"Mean reconstruction error: \", mean_recon_error)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
